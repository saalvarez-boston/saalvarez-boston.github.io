
CS244, Randomness and Computation

:00
Reminders

	PS10 up tonight, due next Tuesday


:02
1D Random Processes

	Some uncertain phenomena involve variation over time

		heart rate signal

		stock price

	We can model such phenomena using sequences of RVs

		X1, X2, ... Xt, ....

	where Xt is a measurement of interest at time t

	We will assume that time is discrete, with t a non-negative integer

	Such a sequence is known as a random process (stochastic process)

		
:05
Example of a random process: repeated measurement of a random variable

	Any RV X produces randomly selected values according to some PMF

	If X is sampled repeatedly, a sequence of such values is produced

		for example, toss a coin 100 times

		measure the length of the line 100 times

		etc.

	Assuming that this multiple sampling experiment is repeated many times,
	the i-th value in the sequence may be viewed as a RV in its own right

		X1, X2, ..., Xi, ... X100

	Since each of these observations originates from the same original RV X,
	the RVs Xi will all have the same PMF - the same one as X

	We will also assume that the various samples are taken independently,
	so that the RVs Xi are independent of one another

	The Xi are said to be independent, identically distributed (iid) RVs

	This is the simplest example of a random process, an iid process


:12
Behavior of iid averages for large sample sizes

	We have become accustomed to viewing the expected value of a RV X as 
	the expected average value of a large number of observations of X

	This idea can be formalized in terms of an iid sequence of RVs

	Indeed, the observations of X are an iid sequence Xi as described above

	We consider the relationship between the sample average

		Xn~ = (X1 + X2 + ... + Xn) / n

	and the expected value E(X)

	We expect that the sample average will be close to the expected value,
	especially if the number of samples, n, is very large


:15
Law of Large Numbers

	(LLN, weak form) If Xi is an iid sequence of RVs with finite variance,
	then the probability that Xn~ and E(X) are more than a distance d apart 
	decreases toward 0 as n becomes very large:

		lim_{n -> infinity} P(|Xn~ - E(X)| > d) = 0

	(LLN, strong form) If Xi is an iid sequence of RVs with finite variance,
	then the probability that Xn~ converges to E(X) as n -> infinity is 1

		P( lim_{n -> infinity} Xn~ = E(X) ) = 1


:20
Central Limit Theorem

	Consider a simulation of repeated coin tosses first

	Examine histogram of average for large time

	The CLT describes the distribution of the limiting averages for iid RVs

	It states that the PMF in the limit is Gaussian, with mean E(X)
	and variance var(X), as it must be


:25
Non-IID random processes

	It is more interesting to consider what happens when the various RV Xt
	that comprise a random process are dependent in some way

	We will study a particular form of dependence, namely that in which
	each RV Xt depends on the value of the RV X(t-1) immediately before Xt

		e.g., Xt = number of people in line at a store

			more likely that Xt=10 if X(t-1)=9 than if X(t-1)=0


:27
Markov chains

	We assume that there is a shared set of possible values of the Xt

	and that the probability that X(t)=vj is observed at time t is 
	determined by what value X(t-1) is observed at time t-1, according 
	to the same table of conditional probabilities for all t:

		p(i,j) = P(X(t)=j | X(t-1)=i)

	The p(i,j) are known as transition probabilities, and are frequently
	represented as arc weights on a graph that has the possible values vj
	as its nodes

	The nodes are usually referred to as the states of the Markov chain

	
:30
Applications of Markov chain models

	Queueing theory (e.g., number of people in line at the DMV)

		Possible states are the non-negative integers 0,1,2,...

		Transition probabilities determined by arrival and service rates

	User modeling for e-commerce

		Possible states of the sort waiting, searching, buying
		
		Transition probabilities can be estimated from user behavior

	Simple model of text

		Possible states can be letters or words

		Transition probabilities describe relative frequency of
		various letter sequences or word sequences


:35
Generating the state sequence of a Markov chain

	For notational convenience, we will assume that the states are
	the positive integers in some range 1...n

	If the state X(0)=i at time 0 is known, then the state X(1) at time 1
	will not be determined, but we know its probability distribution:

		P(X(1)=j) = P(X(1)=j | X(0)=i) = p(i, j) = row i of A,

	where A is the transition probability matrix

	Notice that this can be written as a matrix multiplication:

		P(X(1)=j | X(0)=i) = [0s ... 1 in column i ... 0]*A,

	We will represent distributions as row vectors

		P_X(k) is a row vector with j-th column value equal to P(X(k)=j)

	If the initial state X(0)=i0 is known, then the initial PMF is:

		P_X(0) = [0s ... 1 in column i ... 0]


:40
Markov chain simulation example

	Consider the Markov chain with the following transition matrix:

		A = [0.75 0.25; 0.4 0.6]

	Assume that the chain starts in state X(0)=1

	Then the PMF of the state X(1) at the next time step is:

		P(X(1)=j) = [1 0]*A = [0.75 0.25]

	So, we don't actually know X(1), but we know that X(2) is three times
	as likely to be 1 than it is to be 2

	What about X(2)?

	Well, we know its PMF too, by the chain rule of conditional probability:

		P(X(2)=j) = P(X(1)=1)*P(X(2)=j|X(1)=1) + P(X(1)=2)*P(X(2)=j|X(1)=2)

			= 0.75*0.25 + 0.25*0.6

	Notice that this is also a matrix multiplication:

		P(X(2)=j) = [0.75 0.25]*A = P_X(1)*A

	In fact, we can continue generating the Markov chain PMFs in this way:

		P_X(k+1) = P_X(k)*A

	The matrix multiplications build up, so that we end up with:

		P_X(k) = P_X(0)*A^k

	Let's do this for a few dozen iterations

		[1 0]*A^10 (then 20, then 30)


:47
Simulating a specific state sequence

	Once we have the PMFs, simulating a state sequence is just a matter of
	pseudorandom number generation according to those PMFs

		show runMC example or two

		you'll do this in PS10


:50
Temporal evolution of a Markov chain

	In summary, we will know the PMF for X(k) from that for X(k-1),
	so we can find P_X(k+1) as long as we know the PMF for X(0):

		P_X(k) = P_X(0)*A^k

	where P_X(t) is a row vector that gives the distribution of X(t)

	If P_X(0) specifies a starting state i0, then P_X(k) will simply be
	the i0-th row of the matrix A^k


:52
Stationary behavior of a Markov chain

	Let's revisit the simulation example

		A = [0.75 0.25; 0.4 0.6]

	Suppose that the starting state is now 2 instead of 1

	Calculate the PMF of X(k) for larger values of k

	Anything worth noting about the result?

	It's essentially identical to the PMF that resulted when X(0)=1

	"Typical" Markov chains exhibit this behavior
	(it's enough for some power of A to have no zero elements)

	The consequence is that the Markov chain settles into a "steady state"
	or "stationary" or "equilibrium" PMF after a while

		this doesn't mean that the state sequence is predictable

		just that the probability distribution over states is known

	By the Law of Large Numbers, the stationary distribution satisfies:

		P_X(infinity)(i) = lim_{n -> infty} number of i's in X(1...n)/n


:57
Stationarity and eigenvectors

	Suppose that v is the stationary PMF (row vector) for A

	Since v*A is the PMF for the next timestep, and since the next timestep
	has the same PMF (this is what stationary means), we have:

		v*A = v

	In other words,

		v is a left eigenvector of A with eigenvalue 1

	In fact, this provides a way of determining the stationary PMF:

		find the left eigenvectors of A

		standardize (scale) the eigenvector with eigenvalue 1
		so that its elements sum to 1 (so that it's a PMF)


:60
Example of eigenvector determination of the stationary PMF of a Markov chain

	Back to our 2x2 example

		A = [0.75 0.25; 0.4 0.6]

	We wish to compute the eigenvector-eigenvalue pairs 

	However, note carefully that MATLAB defaults to right eigenvectors

	How to get the left eigenvectors of A?

		remember the following:

			suppose v is a left eigenvector of A (which we seek)

				v*A = cv

			transpose the equation to find

				A'*v' = cv'

			which means that v' is a right eigenvector of A'
 
	So, we can just compute the right eigenvectors of the transpose A'
	and then transpose them to get the left eigenvectors of A

		[vecs vals] = eig(A')

		transpose the 1-eigenvector

		compare it with the stationary PMF found by matrix powers

